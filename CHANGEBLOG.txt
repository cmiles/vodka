=========================== render-env-idea ====================================
---
title: 'Render Environment Idea'
date: "2020-09-24T00:08:19.000-04"
description: In which I think out loud about how to fix rendering.
---
Currently rendering is a bit of a disorganized mess. There are several
different methods for rendering: render just one renderNode (and its
children), render everything, "important" renders that take precedence
over other events in the eventqueue, etc. Calls out to the eventQueue
to enqueue different render actions are sprinkled throughout the codebase
and when you do various actions in the interface, because they are sometimes
needed when that thing happens,
but then this often results in several render
passes happening when one would suffice.

Well-written user interface frameworks usually solve this with a "dirty flag."
When something happens that invalidates a particular portion of the user
interface, it gets marked as dirty or invalid. Later, a render pass redraws
only those things that have been marked dirty.

I have a little complication though, which is the separation of the
RenderNode layer from the Nex layer. If you cram a nex into a nexcontainer,
it's reasonable to say at that point that the nexcontainer's rendernode
is invalid. However I'm not entirely sure it's a good idea to store
a list of RenderNodes inside each Nex (even though I do this now,
primarily to deal with oid's).

I am wondering if I should have a RenderEnvironment object.
This would replace the GarbageCollector and would inherit its functionality,
but would also contain a map from Nexes back to RenderNodes.
You might have a program you were working on and you wanted to
switch back and forth between different rendering environments --
you have a 3d code editing env and a 2d env, or voice-only env.
Maybe certain notions only make sense in the 3d env.
I feel like storing a list of RenderNodes in the Nex is a leaky abstraction,
but if the Nex has a reference to its current RenderEnvironment, and just
calls methods in that environment to notify it that it's dirty,
that it's just been newly created, that its children have changed, etc...
or calls a method in the environment to ask it whether there is
more than one reference to it currently visible (relevant to displaying
oids) -- this feels cleaner to me. And the RenderEnvironment can keep
track of the number of references to each Nex, keep track of which Nexes are
dirty and need to be rerendered, etc.

=========================== in-boxes ====================================
---
title: 'Third Piece: "In Boxes"'
date: "2020-09-06T00:08:48.000-04"
description: In which I describe how I made this piece.
---
So I've published my third piece, which I'm calling "In Boxes." This is square
and has two main parts: a random walk algorithm in the center of the square,
and a poem that is written around the edges, one line at a time, clockwise.

[You can see it here.](https://www.instagram.com/p/CEzF2SVg4UL/) The full
version is more than 2 minutes long but both instagram and twitter
trim videos to one minute. It's okay though, one minute is long enough
to convey the idea, and the word sequence loops three times so you're not missing
much.

The idea for this came from being in quarantine, but also from
being kind of "stuck inside my own head" while in quarantine.
I was looking around at some
random walks on the web and saw some pretty boring ones that involved
just horizontal and vertical movement. This is a common implementation because
of course it's easy and doesn't involve any real math. Not sure if mine
is that much of an improvement, but I took the same thing
and implemented the four possible steps (in the four cardinal directions) as vectors,
then slowly rotated these vectors clockwise. This fills the space in a much more irregular way.

I wanted the random walk to stay in the center of the screen, so I used a weighting
function to skew the probabilities of each of the four possible movements,
so if the walk head gets near the edge of the limit circle, it becomes
less and less likely that it will want to land on that circle,
with probability reaching zero on the circle itself. I didn't experiment
with just putting a hard binary limit, but in the past I've seen poor results
with doing this, so having a gradual slope to zero probably
looks better than it would otherwise. The exact formula is:

```
(_power (_minus %1 (_divided-by @radius @maxradius_)_) (_divided-by %1 %100_)_)
```

Which might look slightly more familiar to you as `(1-x)^(1/10)`.

I wrote the poem after coming up with the visual idea, and as a result this
feels less like a poem and more like an art piece. It's interesting
how that works. It's not my best poem but it gets the job done, I think.

I logged 19 bugs in Vodka while working on this. My approach this time was
to log the bug and just keep going, even if it forced me to compromise
on what I wanted to do. I wanted the lines in the random walk to have
transparency, and I wanted the fade out of the text to start after a second
or two "beat" and then be a faster fade. I wasn't able to do either of
these things because of bugs.

Of course, I could have just stopped working on this and
fixed the bugs, but the problem with doing that is then I just go down
a rabbit hole of software development and the piece ends up taking
forever to be completed (this is what happened with my previous piece).
For this reason I am switching to a phased approach: when making poetry/art/music/whatever
with Vodka, I'll be just making poetry/art/music/whatever -- and, of course,
logging bugs. When I'm done and publish, I'll put on my
engineer hat and fix the bugs I logged while making the previous piece.
My hope is that by doing this,
the bugs I end up fixing first are the ones that really would bother
actual users (because I'm logging bugs when I'm "in user mode").


=========================== experiments ====================================
---
title: Lots of Experiments
date: "2020-09-01T00:09:05.000-04"
description: I'm in pretty deep with these now.
---
Okay I'm running a bunch of experiments now and need to step back and figure out what I want to really do here.

Here are the experiments I'm running:

1. New insertion: this is the thing where I get rid of insertion point and newline nexes, and instead there is a persistent small red dot "insertion pip" that exists wherever you are. You can move it around (after, before, around, inside) by pressing and releasing the shift key.

2. Insertion tab hack: the above experiment with insertion points makes it so that when you create a new container nex, then press tab, instead of descending into the container and creating an insertion point object, essentially nothing happens because the insertion pip is already where it is supposed to be. This initially caused huge problems because the selected node was not what the test thought it was. So I made this hack such that whenever you press tab on a command, or some other lists, a little flag is set, so that the very next time an event is sent to that command (or other list), it will "emulate" the deprecated insertion point nex. This helped... kind of. But see below.

3. Lenient doc format: this is because in the new world I want to have more exacting tests for whether to apply the doc/line/word/letter/separator magic, so there are tests to make sure that the letter is actually inside a word that's inside a line that's inside a doc... etc. This makes tests fail, so this experiment makes those tests more lenient.

Alright so... the tab hack. Let's say you want to type this:

```
(_cons [letter]"A" (__)_)
```
How do you make this? You create a command nex, start typing "cons" -- good so far. Now you want to make the letter nex, "a", inside the cons. In the old world, we press "tab," then "a". With experiments on, our tab hack saves us.

Alrighty. But what if we want to type this?

```
(_@hello [letter]"t" [letter]"h" [letter]"e" [letter]"r" [letter]"e"_)
```

Oh well that's annoying. In the old world, we'd type `@`, then `hello`, then press the right arrow key to create an insertion point after the symbol, and proceed with "there." If I want the old tests to run exactly as-is with the new insertion experiment stuff on, I need to implement a right-arrow hack. Also, embarrasingly, there's *no way to do this* with the new insertion mode.

When I realized this, I started setting the tests that failed this way to "ignore" (hello new feature!). But after a bit I decided to just jump into making two more experiments:

4. Command editor: this is the editor I've been wanting for a while, which is analogous to the lambda editor I already have.

5. Symbol editor: same thing as command and lambda editors, but for symbols.

These new editors fix the ambiguity problem, but also make tests fail. Yay.

So yeah, here I am fixing tests. And it's a pain to fix tests. So I made it less of a pain by re-enabling "headful" chrome for the tests -- so instead of starting chrome in a headless (invisible) mode, it opens up chrome in the foreground while the test is running so you can see what's happening. That was fun, and I then made it so you can step through tests one keystroke at a time, and speed up/slow down the test runner.

Then I got kind of excited and started fixing tests in a non-backward-compatible way, so that these tests now will only pass if the experiments are enabled. My goal was to get them all passing, then go back, reenable the ignored tests that required there to be a command or symbol editor, and fix those too. I would go fast and get to the finish line, get all the tests passing with experiments on! I am a smart developer and can do this!

Except of course, no. I just hit something else -- some tests failing because of something I forgot. I didn't fix deletions: so right now, even though there is a command editor, if you hit backspace with a command selected, it will start deleting letters from the command text. This is not right. This should require re-entering the editor.

However, this raises the question -- what SHOULD happen if you hit backspace? Should it be the same as shift-backspace?

There is something else I wanted to implement -- that's "reparenting delete." That's where you delete an interior node in the tree, but rather than also deleting the child nodes, you reparent its children "in place" -- they take the place of their parent in the grandparent. This essentially flattens the tree structure at that point. If I have this, I can get rid of the stupid thing where hitting enter with an expectation selected evalutes to its contents. I can just let people reparent instead if they want the contents of the expectation. That frees up that keystroke, so I can make it do something that makes more sense, so that hitting enter with an expectation selected activates the expectation. That frees me up to delete the kludgy "auto-activation" that happens when you interactively evaluate a nex that returns an expectation. Instead, in that case you would just hit enter twice, easy.

So that's all great, but shoud I implement all that now, and set up another experiment? Or should I continue doing what I'm doing -- i.e. edit the tests, essentially adding an "enter" before any place where the user would be hitting backspace to edit the text of a command?

I feel like at this point there are failing tests, and they are failing for several different reasons. If I implement reparenting delete, that just adds another reason to the list of reasons why tests are failing. If I then go back to trying to get them to pass again, it will just be harder to figure out why they are failing.

OTOH if I don't implement reparenting delete now, then I have to go through an additional cycle. I'll get all the tests working, then implement reparenting delete, which will break tests, then go back and fix them all again. I am already going to have to do that for this stupid tab hack.

There is something I can do to help make it easier to fix exceedingly munged up tests, making it at least possible for me to move forward and do reparenting delete. I saved all my old goldens, and old tests, before even starting this massive test fixing effort. I could make a way to pass a flag into the test framework so that it runs an entirely different *set* of tests and goldens.

I think this makes it so I can basically break the tests as much as I want, including getting rid of the insertion tab hack (which I hate), and then once I'm done doing damage to them, go through one single pass through to fix them all. If a test breaks and I can't tell why, I can run the test against the original golden directory in `--show` mode, with experiments off so I am getting the old behavior *and* the old tests, grab some popcorn, and watch the test do what it's *supposed* to do. In most cases, even with super broken tests, this should be enough information for me to fix them.

I've done a lot of changes now, and it's been a while since I ran the entire test suite with experiments off -- I will need to do at least one full run that way, comparing against the old goldens, and debug any tests in the old set that break, so I can make sure I'm still at that baseline. Should have thought of that before, but oh well. Cowboy-engineer in me hates debugging deprecated code but, I mean, Cowboy also hates writing tests too... we haven't been listening to Cowboy much lately.

So what's the upshot? Basically this:

1. make a way to specify a "test set" directory when running runtests.sh (so "alltests" is the default, but then maybe you could pass "oldtests" or whatever)
2. save the test results HTML output in the alltests (or whatever it's called) directory, so I don't have to rerun all the tests just so I can compare two different sets of tests/goldens
3. make it so you can pass experiment flags into runtests.sh (probably by just passing in query string params, that then get passed into the headless or headful chrome instance)

I feel like I might be creeping toward a world where I partition the tests into "test sets" in different directories, just to make my test runs faster/more targeted/just only testing what I'm working on/etc., so that running the full suite goes through all the test dirs and tests each one.

After all this though... I still think I should wait to implement reparenting delete. Fixing the tests is a matter of just putting in a few "Enter" keystrokes at the right places, so it will invoke the editor instead of relying on the old way of deleting characters from the command text. Then, for now, I just make backspace and shift-backspace the EXACT same thing for nodes that have editors.


=========================== tag-types ====================================
---
title: Tag types
date: "2020-08-17T00:10:46.000-04"
description: I guess we need two types of tags.
---
I want to make it so that the instantiate function works like this:

```
~(_instantiate ^<'Tagname'>_)
```

Or like this:

```
~(_instantiate (<'Tagname'>)_)
```

In the first example, it's a null that we are passing to the function, tagged with
the name of the template we want to instantiate. In the second, it's an org,
and in that case we merge the contents of the passed-in org with the contents
of the org we instantiated.

The idea of passing a null is great, because it makes this really clear:

```
~(_~(_<'methodname'>instantiate ^<'Classname'>_) ...method args..._)
```

The null tells it which template to instantiate and then the tag on the instantiate
call itself says to dereference whatever is returned. So instantiate an object,
then call one of its methods right away. It makes sense, because the two primary
usages of the tag are 1. telling it what to dereference 2. labeling things
so you can find them again via dereferencing. This is... neither type of usage.

This of course makes you think -- what if you nest calls to instantiate?

```
~(_instantiate ~(_<'class2'>instantiate ^<'class1'>_)_)
```

This doesn't work.

See, we want the nested expression to instantiate the class, NOT dereference,
and then we want the 'class2' tag to be used by the function we are passing the
return value TO, like in the previous example.
But this doesn't work, because the instantiate function
creates a NEW object, returning it. That returned object thing has all new tags.

Not to mention if that thing had a method named class2, that would get dereferenced.

I have to think more about this. Like, do I make a separate type of tag that is
a "dereference" tag that, instead of staying with the object itself, stays
at the invocation site, and regardless of what is returned, it will dereference
that?

Maybe I just need to pass two args to instantiate, so I always pass
the null with tag for the first arg, then optionally the second param.

Another problem with this approach is that, even if you tried to propagate
the tag from the thing passed in, the returned thing has to be
tagged with the classname of that inner-thing you just instantiated.
The result of this is that when you are calling the outer instantiate,
it won't know what you want to instantiate, because it will have both
tags 'class1' and 'class2'.

Yeah I think for now we need to use the two-arg form until I get more used
to these tags and how they can be used.


=========================== cursor-command-type ====================================
---
title: A Cursor Command Type?
date: "2020-05-31T00:08:52.000-04"
description: Brief sketch for an idea to replace KeyResponseFunctions.
---
Previously I was thinking that custom nexes would tell the IDE/REPL how to treat them
by returning a map from strings representing an input name (for example, 'ShiftEnter') to strings, where each
string is a type of response function (for example, 'MoveToNextSibling'). However I
think I've come up with a better idea.

What if I created a "cursor command" primitive data type? Maybe it's a custom org
or something. So maybe not a primitive. But some complex data type that encodes information
about what the IDE should do in response to a given input. Where to put the cursor/selection,
whether to evaluate the nex, where to put the evaluted nex, etc. Then, each
nex can implement a function that is passed the actual key input (like 'ShiftEnter')
and it will return a "CursorCommand" object.

Then, I can set up a bubbling algorithm of some kind. So when an IDE event, like a click
or keystroke, happens, we first try the selected nex. If it returns Nil from
getCursorCommand, we try its parent, and then its parent, on and on up the tree.
We can do this because it's the IDE doing this, not code, thus we are in RenderNode
world, not plain-old-nex world.

If we bubble all the way up, then we'll have some kind of default handler at the root.
Which would implement, you guessed it, the default algorithms I already have
implemented.

This is, of course, another huge refactor. But worth thinking about.

=========================== nothing-to-see-here ====================================
---
title: Nothing to See Here
date: "2020-05-23T00:08:50.000-04"
description: In which I realized it was a trivial fix...
---
Ah.

I was creating a new scope when a closure was created (when its lambda was evaluated.)

Why would I do that?

You make a new scope when you evaluate the command containing the closure as its
first argument. Of course.

Fixing this fixed the animation issue. I really hope this is now put to bed, and this
misadventure with copying values in the environment object is over.

=========================== where-to-from-here ====================================
---
title: Where to From Here With Expectations...
date: "2020-05-22T00:17:10.000-04"
description: Two potential plans made.
---
Okay so I've repaired some of the damage made by me not using my brain. SICP-style
encapsulation of closure scopes works.

This is the problem though: I have to decide what to do about expectations.
The current implementation of `fade-in-for-seconds` now has a bug where
every new animation you start replaces all the info from the old animation.
In other words, if you fade in something for 60 seconds, then 30 seconds into
the animation you try to do this again on another nex, the new animation will
start as you expect, but the old animation (which was halfway through)
will restart (because all the temporary variables get replaced by new values)

I can possibly fix this by having a producer function that makes a new scope/closure,
and then runs it, every time you do an animation.

I tried initially just doing this when assigning an expectation a new ff-with:

```
    this.ffClosure = closure.makeCopy();
```

This would make a totally separate memory space for each expectation. This caused
some other weird problem and I'm not sure it makes sense.

=========================== mistakes-were-made ====================================
---
title: Mistakes Were Made
date: "2020-05-22T00:10:40.000-04"
description: In which I self-reflect on how I was super wrong in a previous decision.
---

In a previous investigation, I looked at the following code fragment:

```
let f = function() {
    let a = [];
    for (let i = 0; i < 10; i++) {
        let r = Math.random();
        a.push(function() {
            console.log(r);
        });
    }
    return a;
}
let m = f();
m[0](); // prints 0.4358334282486591
m[1](); // prints 0.8695053811494855
m[0](); // prints 0.4358334282486591
```

And used this as evidence or justification for the fact that, when you create a closure,
it should contain a copy of the entire environment which would vary independently from any
other closures -- i.e. copy all the scopes all the way up
to the root. The reason I thought that is that I was reading this
JavaScript code wrong. The way I was seeing it was that
 `r` was in the parent scope for all 10 of the functions
created inside the `for` loop. Since each of the 10 generated functions had a different value of `r`, it must be making a copy
of the parent scope. Right?

But that's not how JavaScript works.  In JS, there are other ways to get new scopes
besides making closures. Each `for` loop gets its
own scope.
This is true in regular Lisp too, but not Vodka (yet?). In the
above code snippet, the parent scope is the scope in the 
`for` loop, which gets recreated every time the `for` loop is
executed -- that's how loop scopes work in C-like languages.

Look what happens when I define the `r` variable in the top level function's
scope:

```
let f = function() {
    let a = [];
    let r = 0;
    for (let i = 0; i < 10; i++) {
        r = Math.random();
        a.push(function() {
            console.log(r);
        });
    }
    return a;
}
let m = f();
m[0](); // prints 0.5167996541520334
m[1](); // prints 0.5167996541520334
m[0](); // prints 0.5167996541520334
```

Ugh. This is the behavior I expected when I first tried this
experiment.

This might be more clear if I replace the `for` loop
braces with something more Vodka-like:

```
let f = function() {
    let a = [];
    for (let i = 0; i < 10; i++) (function() {
        let r = Math.random();
        a.push(function() {
            log(r);
        });
    })();
    return a;
}
```

This would have worked fine in Vodka before I made that
copy-the-entire-environment change. And the
copy-the-entire-environment changes breaks a lot of stuff,
like the exact pattern from SICP where a function defines
state, then returns a setter or getter function for
that state. So we need to go back to how it was before.

It's probably good that I made this mistake, because it forced
me to create a closure class. However, one potential issue is that I think expectations
should still have their own full scope copies, so you don't have different expectations trampling over each others' memory. 


============================ closure-memory-problems-again ====================================


---
title: More Closure Memory Problems
date: "2020-05-10T00:04:00.000Z"
description: In which I realize I'm not out of the woods when it comes to copying closure memory...
---

Just hit what looks like a bad bug/oopsie. Again.

This javascript code:

```
(function() {
    let a = 10;
    let b = function() {
        a = 100;
    };
    b();
    return a;
})();
```

returns 100. The inner function gets its own scope, but the next-level-up scope refers to the
scope in the parent, so running the inner function can change the value of this variable
in the parent scope.

This is how I remember this was supposed to work, from SICP.

There is a Vodka test that runs equivalent code -- it's `functions_basic_set`, and the Vodka code is this:

```
~(
  &(
    ~(let @a #10)
    ~(let @b &(
      ~(set @a #100)
    ))
    ~(b)
    @a
  )
)
```

This code returns 10. Dang. I changed ALL of this recently
because of something else (also documented in previous entries in the blog). And I guess I broke this
behavior.



================================ moving-defaulthandler ====================================


---
title: Moving around defaultHandler
date: "2020-05-10T00:00:00.000Z"
description: In which I ramble about some refactoring I'm doing...
---

I've moved `defaultHandler` stuff into the new `keyresponsefunctions.js` file. The reason
I did this is that I want to see all these functions together -- there's a lot of similarity
and I think they can be boiled down into something that makes more sense. However
it's not entirely clear what yet. Also it has to do with deps: if I don't do this,
then practically every nex will have to depend on `Letter` and `Separator`, which doesn't
really make sense from a logical standpoint. `keyresponsefunctions.js` already depends on
ALL the nex types so this makes more sense.

The `defaultHandler` code is really deprecated anyway. I think the best way to do this
would be that each nex specifies, for keystrokes that don't fit into the category
of "control keys" (like arrow, esc, tab, etc):
- a regex indicating the keys it intercepts/responds directly to (e.g. for bools, that's 'y' and 'n')
- an insertion strategy for keys it doesn't intercept (i.e. word-level, letter-level, etc - the
  stuff I implemented to preserve doc structure)

EXCEPT WAIT.
- the `Doc` insertion stuff will eventually be handled by custom nexes implemented with orgs
- when I start implementing accessibility features in earnest, we will need to think about what
  'keystrokes' even mean, and in fact all editing of nexes will happen via editors (where the
  editor type depends on input mode, so for strings there would a voice input mode and a
  keyboard input mode)

so - that said -- it's all deprecated. It's just all deprecated.

SO MAYBE it would just be better to put in comments to that effect, PUT IN the unnecessary
dependencies (mark THEM also as deprecated) and not bother spending a bunch of time fussing
about it. Why refactor these methods when I'm going to be deleting them all hopefully soon?

ALSO. Let's talk about editors for a second. I like that you don't have to press "enter"
after editing a bool. How can I fix that? (The editor situation is garbage right now - for
example, the string editor) I wonder if I can/should refactor the editor code so that
certain editors just take ONE keystroke and then exit.



====================== difference-between-builtin-foreign ===================================


---
title: The Difference Between Builtins and Foreign Lambdas
date: "2020-05-09T00:00:00.000Z"
description: In which I explain why I have two different ways to do the same thing...
---

Why did I create two different subtypes of `Lambda` that run javascript code? i.e.
`Builtin` and `ForeignLambda`/`ForeignClosure`?

`Builtin`s are meant to be part of the core language. They are bound at the root environment
and are always in scope. They have full access to their args and can conditionally
evaluate some or not evaluate some depending on whatever they want to do (c.f. conditional
evaluation in `if` and, in the future, in `or`, `and`). They can return any Vodka
data type, initialized in any way.

Foreign functions have their function arguments automatically converted back and
forth between js data types and Vodka data types. For this reason, some data types
won't really translate. The same goes for their return values. They are not bound
to anything globally and are meant to be used inside `NativeOrg`s, so not directly
seen by the programmer. They can't return `EError`s (however I do have to think about
how error handling will work with foreign functions, maybe they can return a specific
error string or something).

In a future world, I might open things up so that people could plug in their own
extensions to Vodka by just dropping a JS file somewhere with functions in it. This
would work via foreign functions rather than builtins.



============================ storing-data-in-closures ===================================


---
title: Storing Data in Closures
date: "2020-04-29T00:00:00.000Z"
description: In which I decide that a JS bug was a Vodka bug...
---

I thought about it and I decided I'm willing to say that the problem with the stale closure
from `fade-in-for-seconds` is the fault of the Lisp programmer Jason, not the javascript programmer
Jason. Closures really aren't a great place to store data. I'm just doing it this way
because it's the only thing I have implemented, other than lists. I think it highlights for
me the importance of getting orgs working. However I did have one thought: if it's possible
to store data in a closure, then in some sense they are like structs or objects.
So we can't we have accessor methods that look up data in a closure, if you have a
reference to one? Or that even allow you to modify it. Might be helpful for debugging.
Could we erase the distinction between closures and objects/orgs?

In other news, copying expectations failed because I wasn't activating the newly
copied expectation if the old one was already activated. This is a bit questionable
anyway because maybe you don't want to do that, right? Let's say you have a long
running process/animation that takes 20 minutes and you are 19 minutes through it.
When you copy it, it resets the clock for the copied one. Here's the thing though,
if I don't do that, then if I copy a list that contains an animation,
like I do whenever I apply styles, the animations in the newly copied list will
not be activated.

What to do.

Oh also, I would have to make sure I copy the children of a list before copying the
fields of the list because activating does different things depending on whether
an exp has children or not.

I guess I could write a function that reactivates any nodes that are not activated.

I am getting to the part of the development process where the right thing to do is
not always obvious -- which is, I guess, why I'm writing this stuff down.


============================= copy-environment ======================================


---
title: Copying Environments
date: "2020-04-28T00:00:06.000Z"
description: More wrestling around copying environments.
---

When we copy an environment, we don't copy the environments of closures in the environment.

When we create a closure, we copy its environment, because we want that closure to have its
own private copy of all those variables. However we don't copy the environments of the closures
referred to in the environment being copied, because then those closures wouldn't have their
own memory space that can vary independently.

Right? This is how we are able to have "lexical" environment. Each closure is generated
from a different place in the source code.

But when we copy expectations we can have subtle bugs. Currently, in `animation-functions`,
when you call `fade-in-for-seconds`, `do-on-every-for` creates a closure with a local environment
that captures a `val` variable which is supposed to encode the value to set the opacity to.
That closure gets passed into `do-on-every-for`, and it's called `f`.

`do-on-every-for` creates an expectation. That expectation has an `ff-with` closure.
The `ff-with` closure has a local environment with a reference to `f`.

When the expectation returned by `do-on-every-for` is copied, its closure is copied,
and that environment is copied. But the environment in the closure pointed to
by `f` is NOT copied, so the next time it's called, it still has the final value
that it had the last time the animation ran through from 0 to 1. So it will
run through again, from 1 to 2.

I'm not sure why this causes problems with async code but not with normal lisp.
I'll have to think about that. It seems like it would be infeasible to copy
the environment differently when copying the closures inside expectations.
it is a different use case for sure (copying because you're creating a closure
vs. copying because you're copying an expectation) so it seems logically
justifiable. However the problem is that it's not just symbols in the environment
pointing to closures -- you could store a closure in a list, or in a list inside
a list, etc. So I'll have to think about it.

I'll also have to do an experiment in JS or real Lisp to verify my original assumption, i.e.
the first sentence of this entry: "when we copy an environment, we don't copy the environments
of closures in the environment."

I mean in both cases we are copying environments, but for different reasons:

1. we are copying environments so each closure has its own copy of the values of
things in the lexical part of the code where the closure was created

2. we are copying environments so the copied expectation has a snapshot in time
of the entire memory space of the program at the time it was copied, so when it is
activated or fulfilled later the program hasn't changed unexpectedly



=========================== activation-function-generator ================================


---
title: Activation Function Generator
date: "2020-04-28T00:00:00.000Z"
description: Wrestling with some bugs around copied expectations that call async js functions.
---

Here's how I was going to deal with bridging between actual asyncronous javascript functions
(like loading files, timeouts, etc) and expectations:

- builtin calls `getCallbackForSet`, which returns a callback that fulfills the expectation
- builtin makes its own javascript closure capturing necessary lexical environment which
  does something asyncronous (like load or save a file), then calls the callback
- builtin makes a call to `set` passing the javascript closure it just made. That closure
  is the "activation function". When activate is called, the activation function is called
  and the asyncronous process is kicked off.

however this won't work because if the expectation is copied, it's expected that
both copies will still be able to be activated. But if they both get the same activation
function they will fulfill the same expectation (the original one) because there's no
way to copy a function in js.

What I need the builtin to do is give this expectation an activation function generator.

The builtin would call it like this:

```
let e = new Expectation();
e.set(function(callback) {
  return function() {
    let f = loadFile(function(loadedFile) {
      callback(loadedFile);
    });
  }
})
```

So it's, annoyingly, three nested closures, but there's no way around it.
- Outer closure generates an activation function.
- Middle closure is the activation function, which gets called when the exp gets activated
- Inner closure is the callback from whatever async operation is being actually done.

Also: yesterday  I was dealing with trying to suppress activation of expectations in different places.
I made a way to indicate suppressing activation in the param list of a function,
but then I also made a way to suppress activation from the return value of a function.
However I think this is bad.  It seems like you might get in a fight where a certain call site
has a return value set to skip activation but it's an arg that doesn't skip activation,
and it's hard to debug - precedence rules -- blah blah annoying and complicated.
I think we might need to pick where we want to suppress activation.

The current situation: the loop primitive doesn't work with `fade-in` (thought it might work with other ones).
It's looping alright, but something about the way `fade-in` works is storing
the opacity value in a closure somewhere so that every time it loops
it keeps incrementing past one (I debugged after 20 iterations
and it was setting the opacity to 20.183333)




================================= skip-activate ================================================


---
title: Skipping Activation
date: "2020-04-25T00:00:00.000Z"
description: A short post with some ideas around skipping activation of expectations.
---

Expectations are either activated when they are evaluated, or not. Every param to a function
is evaluated of course, but what if I had an equivalent to "skipeval"
but just for expectations, like "skip activate"?
So it would be indicated by a comma instead of a * in the type signature.


============================== copying-expectations ==========================================


---
title: Copying Expectations
date: "2020-04-20T00:00:00.000Z"
description: A continued analysis of the bug I was wrestling with in the previous blog entry.
---

Copying expectations sort of works but still doesn't work.

Here's the code for `do-on-every`:

```
(& f nex interval
  (~let @exp (~cons @nex (* )))
  (~let @fff (& n
    (~reset @exp)
    (~ff-with @exp @fff)
    (~set-delay @exp @interval)
    (~f @n)
  ))
  (~set-delay (~ff-with @exp @fff) @interval)
)
```

"Reset" is not being called on the correct expectation. it has a stale pointer to
some other expectation that is not the one that was copied.
Which makes sense, because when we copy this expectation, we don't
update anything that points to it.

This is not caused by the fact that we copy the closure when we copy the expectation.
Even if we didn't copy the closure, the closure owned by the copied
expectation would still point to the wrong thing. In fact, it would be worse,
because it would point to the same (original) expectation that was discarded
after the copy, which means that that expectation would get ff called on it twice.
Worse? Better? IDK, just wrong differently. Maybe better because it wouldn't
fail as silently. This fails silently because the copied expectation is distinct
but is still not the one on the screen.

It could be fixed by having `ff-with` take the expectation as its argument
rather than the contents of the expectation. The return value of `ff-with`
would still be the new contents of the expectation. It's just that you'd
have to get the car if you didn't want to reset the expectation.

I could put in some error checking to prevent you from accidentally returning
the expectation from `ff-with` (this would be a common mistake and basically
would always be wrong).

This is a very flexible solution in that you could ostensibly do other things like
chain the expectation to other things etc. Also the expectation itself is the
"most you know" at fulfill time, i.e. you can't go higher to the parent but
you do have a pointer to the expectation that is being fulfilled.

I'm not sure I can think of a fancier/better solution.




================================= multiple-closures ===========================================


---
title: Multiple Closures
date: "2020-04-19T00:00:00.000Z"
description: An analysis of a bug I ran into. Another blog entry that started life as a code comment.
---

When a function creates multiple closures, each one needs its own set of symbols
that can vary independently.

```
let f = function() {
    let a = [];
    for (let i = 0; i < 10; i++) {
        let r = Math.random();
        a.push(function() {
            console.log(r);
        });
    }
    return a;
}
let m = f();
m[0](); // prints 0.4358334282486591
m[1](); // prints 0.8695053811494855
m[0](); // prints 0.4358334282486591
```

When we do copy, we can make shallow copies - example:

```
let f = function() {
   let a = [1, 2, 3];
   let funcs = [];
   for (let i = 0; i < 10; i++) {
      funcs.push(function() {
         console.log(a[0]);
         a[0] = i;
      });
   }
   return funcs;
}

let fs = f();
fs[0](); // prints 1
fs[3](); // prints 0
fs[0](); // prints 3
```

Each function gets its own private copy of a that it can modify, but the contents of a are shared.

```
let f = function() {
    let a = [];
    for (let i = 0;i < 10; i++) {
        let r = Math.random();
        a.push(function() {
            console.log(r);
        });
    }
    return a;
}
let m = f();
m[0]();
 // prints 0.4358334282486591
m[1]();
 // prints 0.8695053811494855
m[0]();
 // prints 0.4358334282486591
```

- the lambda needs to return a closure when it is evaluated
- a closure needs to be a separate object
- a closure has a pointer to an environment
- the environment that it points to is a copy, going ALL THE WAY UP THE STACK TO THE ROOT
of the environment that existed at the time the lambda was evaluated




====================================== type-system ===========================================


---
title: Type System Ideas
date: "2020-04-15T12:00:00.0Z"
description: More of a checklist than a blog entry. This blog entry started out as a comment in the code.
---

Here's my type system:

DONE - a tag is an identifier associated with a program element

DONE - a org is a special list

DONE - an org can have children that are tagged

DONE - at evaluation time, if an expression is tagged, the evaluator will check after evaluation
to see whether the expression evaluated to an org. If it did, then the evaluator will
retrieve the child matching the tag, and evaluate that

if an expression has multiple tags, the evaluator will resolve them in the order they are specified,
and use the first one that works (note: need to think more about this because what if an obj has multiple children with the same tag, what if a nex has two of the same tag, etc)

DONE - It is not an error if the returned org doesn't have that tag (unless strict mode?)

DONE - If dereferencing the tag returns another org, the evaluator will dereference again. It will keep dereferencing until: 1. the dereferencing step stops returning orgs or 2. it runs out of matching tags

types:
- the type of an integer, string, etc. is just that
- the type of a lambda is a specifier containing its return value, args, etc
- the type of an org is an unordered list of tags. an org is of a given type if it contains all the tags
  in the list
- a contract is some trustable assertion about a tag, as in "you know that something with this tag is _blank_".
  - contracts are enforced at the time the tag is assigned to the nex
  - types of contracts
    - identity contract: a tag can only be assigned to a specific object
    - equality contract: a tag can only be assigned to an object that evaluates as equal to a given value
    - simple type contract: something with tag Foo must be an integer
    - lambda exclusive type contract: something with tag Foo must be a lambda with the exact type string -# arg# arg#
    - lambda inclusive type contract: something with tag Foo must be a lambda that could allow arguments that match a given type string
    - list exclusive tag contents contract: something with tag Foo must be an list containing things with
      tags Foo, Bar, and Baz and nothing else (note: it doesn't have to be an org, but if it's not an org,
      it can't be dereferenced)
    - list inclusive tag contents contract: something with tag Foo must be an list containing things with tags
      Foo, Bar, and Baz, but it could have other things
    - list exclusive type contents contract: something with tag Foo must be a list with two integers and nothing else (or whatever)
    - list inclusive type contents contract: something with tag Foo must be a list with at least two integers, could have other things
    - something with tag Foo must also have tags Bar, Baz, and Qux (this is how you do 'contract contract', i.e. enforce
      that a nex satisfies multiple contracts)
    - custom contract: you implement a function in Vodka that returns true or false, and at contract-check time
      the framework evaluates your function, passing in the nex that is being checked for whether it satisfies the contract
      
Contracts are only checked at tag assignment time for performance reasons, but there can be a primitive that re-checks contracts

- a kind is an restriction that states that a given tag can only be assigned to something with a given type
- lambda type strings can also include tags, which indicate that the thing passed in must have that tag

Examples of lambda type strings:


expression | meaning
--- | ---
`arg1`&nbsp;`arg2` | two args of any type
`arg1# arg2#` |   two integers
`arg1! arg2!` |   two booleans
`arg1& arg2&` |  two lambdas
`arg1* arg2*` |  two expectations
`arg1@ arg2@` | two symbols
`_arg1@ arg2@` | two symbols, but the first one is not evaluated before being passed
`arg1% arg2#...` | a float and then zero or more integers (variadic argument)
`arg1% arg2#?` | a float and then an optional integer
`_arg1~ arg2~` | two commands - the first is unevaluated, but the second needs to be returned by the evaluation step for the second argument
`arg1( arg2(` | two lists
`arg1#`&#8288;`[Magnitude]`&nbsp;`arg2#` | two integers, but the first one has to be tagged with 'Magnitude'
`arg1) arg2)` | two orgs, any type
`arg1)[Magnitude]`&nbsp;`arg2)` | two orgs, but the first one has to be tagged with 'Magnitude'
`-# arg1#` | this function takes an integer and returns an integer
`-)[Magnitude]`&nbsp;`arg1#` | this function takes an integer and returns an obj tagged with 'Magnitude'




Experimental features regarding return values:

expression | meaning
--- | ---
`-` | setting '-' would set the return value
`-#?` |    this function can return an integer but it can also return 'nothing', which means the evaluator removes whatever it returned from the arg list of what it was in.
`-#...` |     this function can return more than one thing
`_-` |     this function is not evaluated, see below.

Unevaluated functions:

So if you had:

    `(~bind @do-not-do (&_-# (~+ #3 #3)))`

we have a function that adds 3 + 3 and returns an integer, but it's not evaluated. This means that if you have this:

    (~+ #9 (~do-not-do))

It fails because the `(~do-not-do)` is basically treated like it's been quoted, but this:

    (~+ #9 (~eval (~do-not-do)))

Would work fine because "skip eval" only applies to the first time basically, that is to say, if a "do not eval" function is evaluated, it loses its "do not eval" status.

- make it so that anything inside braces in a tag, i.e. [] is ignored (use this for comments?)
